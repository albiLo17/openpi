{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import dataclasses\n",
                "\n",
                "import jax\n",
                "\n",
                "from openpi.models import model as _model\n",
                "from openpi.policies import droid_policy\n",
                "from openpi.policies import policy_config as _policy_config\n",
                "from openpi.shared import download\n",
                "from openpi.training import config as _config\n",
                "from openpi.training import data_loader as _data_loader\n",
                "\n",
                "import os\n",
                "os.environ[\"OPENPI_DATA_DIR\"] = \"/proj/rep-learning-robotics/users/x_alblo/openpi/.cache\"\n",
                "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.9\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Policy inference\n",
                "\n",
                "The following example shows how to create a policy from a checkpoint and run inference on a dummy example."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f6115a08598b4b538d31b3b2faed664f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0.00/10.1G [00:00<?, ?iB/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-10-23 11:39:56.963385: W external/xla/xla/service/platform_util.cc:211] unable to create StreamExecutor for CUDA:0: CUDA error: : CUDA_ERROR_DEVICE_UNAVAILABLE: CUDA-capable device(s) is/are busy or unavailable\n"
                    ]
                },
                {
                    "ename": "RuntimeError",
                    "evalue": "Unable to initialize backend 'cuda': INTERNAL: no supported devices found for platform CUDA (you may need to uninstall the failing plugin package, or set JAX_PLATFORMS=cpu to skip this backend.)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mXlaRuntimeError\u001b[39m                           Traceback (most recent call last)",
                        "\u001b[36mFile \u001b[39m\u001b[32m/proj/rep-learning-robotics/users/x_alblo/openpi/.venv/lib64/python3.11/site-packages/jax/_src/xla_bridge.py:915\u001b[39m, in \u001b[36mbackends\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    913\u001b[39m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m backend = \u001b[43m_init_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplatform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    916\u001b[39m _backends[platform] = backend\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/proj/rep-learning-robotics/users/x_alblo/openpi/.venv/lib64/python3.11/site-packages/jax/_src/xla_bridge.py:1001\u001b[39m, in \u001b[36m_init_backend\u001b[39m\u001b[34m(platform)\u001b[39m\n\u001b[32m   1000\u001b[39m logger.debug(\u001b[33m\"\u001b[39m\u001b[33mInitializing backend \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, platform)\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m backend = \u001b[43mregistration\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfactory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[38;5;66;03m# TODO(skye): consider raising more descriptive errors directly from backend\u001b[39;00m\n\u001b[32m   1003\u001b[39m \u001b[38;5;66;03m# factories instead of returning None.\u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/proj/rep-learning-robotics/users/x_alblo/openpi/.venv/lib64/python3.11/site-packages/jax/_src/xla_bridge.py:693\u001b[39m, in \u001b[36mregister_plugin.<locals>.factory\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    692\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m distributed.global_state.client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m693\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxla_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_c_api_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplugin_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdated_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    695\u001b[39m distribute_options = {\n\u001b[32m    696\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnode_id\u001b[39m\u001b[33m'\u001b[39m: distributed.global_state.process_id,\n\u001b[32m    697\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnum_nodes\u001b[39m\u001b[33m'\u001b[39m: distributed.global_state.num_processes,\n\u001b[32m    698\u001b[39m }\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/proj/rep-learning-robotics/users/x_alblo/openpi/.venv/lib64/python3.11/site-packages/jaxlib/xla_client.py:207\u001b[39m, in \u001b[36mmake_c_api_client\u001b[39m\u001b[34m(plugin_name, options, distributed_client)\u001b[39m\n\u001b[32m    206\u001b[39m   options = {}\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_xla\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_c_api_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplugin_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistributed_client\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[31mXlaRuntimeError\u001b[39m: INTERNAL: no supported devices found for platform CUDA",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m checkpoint_dir = download.maybe_download(\u001b[33m\"\u001b[39m\u001b[33mgs://openpi-assets/checkpoints/pi0_fast_droid\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Create a trained policy.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m policy = \u001b[43m_policy_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_trained_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Run inference on a dummy example. This example corresponds to observations produced by the DROID runtime.\u001b[39;00m\n\u001b[32m      8\u001b[39m example = droid_policy.make_droid_example()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/proj/rep-learning-robotics/users/x_alblo/openpi/src/openpi/policies/policy_config.py:57\u001b[39m, in \u001b[36mcreate_trained_policy\u001b[39m\u001b[34m(train_config, checkpoint_dir, repack_transforms, sample_kwargs, default_prompt, norm_stats, pytorch_device)\u001b[39m\n\u001b[32m     55\u001b[39m     model.paligemma_with_expert.to_bfloat16_for_selected_params(\u001b[33m\"\u001b[39m\u001b[33mbfloat16\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     model = train_config.model.load(\u001b[43m_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrestore_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparams\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbfloat16\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     58\u001b[39m data_config = train_config.data.create(train_config.assets_dirs, train_config.model)\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m norm_stats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# We are loading the norm stats from the checkpoint instead of the config assets dir to make sure\u001b[39;00m\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# that the policy is using the same normalization stats as the original training process.\u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/proj/rep-learning-robotics/users/x_alblo/openpi/src/openpi/models/model.py:310\u001b[39m, in \u001b[36mrestore_params\u001b[39m\u001b[34m(params_path, restore_type, dtype, sharding)\u001b[39m\n\u001b[32m    307\u001b[39m params_path = pathlib.Path(params_path).resolve() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(params_path).startswith(\u001b[33m\"\u001b[39m\u001b[33mgs://\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m params_path\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m restore_type \u001b[38;5;129;01mis\u001b[39;00m jax.Array \u001b[38;5;129;01mand\u001b[39;00m sharding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     mesh = jax.sharding.Mesh(\u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, (\u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m,))\n\u001b[32m    311\u001b[39m     sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec())\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ocp.PyTreeCheckpointer() \u001b[38;5;28;01mas\u001b[39;00m ckptr:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/proj/rep-learning-robotics/users/x_alblo/openpi/.venv/lib64/python3.11/site-packages/jax/_src/xla_bridge.py:1115\u001b[39m, in \u001b[36mdevices\u001b[39m\u001b[34m(backend)\u001b[39m\n\u001b[32m   1090\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdevices\u001b[39m(\n\u001b[32m   1091\u001b[39m     backend: \u001b[38;5;28mstr\u001b[39m | xla_client.Client | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1092\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[xla_client.Device]:\n\u001b[32m   1093\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Returns a list of all devices for a given backend.\u001b[39;00m\n\u001b[32m   1094\u001b[39m \n\u001b[32m   1095\u001b[39m \u001b[33;03m  .. currentmodule:: jaxlib.xla_extension\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1113\u001b[39m \u001b[33;03m    List of Device subclasses.\u001b[39;00m\n\u001b[32m   1114\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1115\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m.devices()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/proj/rep-learning-robotics/users/x_alblo/openpi/.venv/lib64/python3.11/site-packages/jax/_src/xla_bridge.py:1049\u001b[39m, in \u001b[36mget_backend\u001b[39m\u001b[34m(platform)\u001b[39m\n\u001b[32m   1045\u001b[39m \u001b[38;5;129m@lru_cache\u001b[39m(maxsize=\u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# don't use util.memoize because there is no X64 dependence.\u001b[39;00m\n\u001b[32m   1046\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_backend\u001b[39m(\n\u001b[32m   1047\u001b[39m     platform: \u001b[38;5;28;01mNone\u001b[39;00m | \u001b[38;5;28mstr\u001b[39m | xla_client.Client = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1048\u001b[39m ) -> xla_client.Client:\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_uncached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplatform\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/proj/rep-learning-robotics/users/x_alblo/openpi/.venv/lib64/python3.11/site-packages/jax/_src/xla_bridge.py:1028\u001b[39m, in \u001b[36m_get_backend_uncached\u001b[39m\u001b[34m(platform)\u001b[39m\n\u001b[32m   1024\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m platform\n\u001b[32m   1026\u001b[39m platform = (platform \u001b[38;5;129;01mor\u001b[39;00m _XLA_BACKEND.value \u001b[38;5;129;01mor\u001b[39;00m _PLATFORM_NAME.value \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m bs = \u001b[43mbackends\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m platform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1030\u001b[39m   platform = canonicalize_platform(platform)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/proj/rep-learning-robotics/users/x_alblo/openpi/.venv/lib64/python3.11/site-packages/jax/_src/xla_bridge.py:931\u001b[39m, in \u001b[36mbackends\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    929\u001b[39m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    930\u001b[39m         err_msg += \u001b[33m\"\u001b[39m\u001b[33m (you may need to uninstall the failing plugin package, or set JAX_PLATFORMS=cpu to skip this backend.)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(err_msg)\n\u001b[32m    933\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m _default_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    934\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config.jax_platforms.value:\n",
                        "\u001b[31mRuntimeError\u001b[39m: Unable to initialize backend 'cuda': INTERNAL: no supported devices found for platform CUDA (you may need to uninstall the failing plugin package, or set JAX_PLATFORMS=cpu to skip this backend.)"
                    ]
                }
            ],
            "source": [
                "config = _config.get_config(\"pi0_fast_droid\")\n",
                "checkpoint_dir = download.maybe_download(\"gs://openpi-assets/checkpoints/pi0_fast_droid\")\n",
                "\n",
                "# Create a trained policy.\n",
                "try:\n",
                "    policy = _policy_config.create_trained_policy(config, checkpoint_dir)\n",
                "except Exception as e:\n",
                "    print(f\"Error creating trained policy: {e}\")\n",
                "    import os\n",
                "    os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
                "    policy = _policy_config.create_trained_policy(config, checkpoint_dir)\n",
                "\n",
                "# Run inference on a dummy example. This example corresponds to observations produced by the DROID runtime.\n",
                "example = droid_policy.make_droid_example()\n",
                "result = policy.infer(example)\n",
                "\n",
                "# Delete the policy to free up memory.\n",
                "del policy\n",
                "\n",
                "print(\"Actions shape:\", result[\"actions\"].shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Working with a live model\n",
                "\n",
                "\n",
                "The following example shows how to create a live model from a checkpoint and compute training loss. First, we are going to demonstrate how to do it with fake data.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config = _config.get_config(\"pi0_aloha_sim\")\n",
                "\n",
                "checkpoint_dir = download.maybe_download(\"gs://openpi-assets/checkpoints/pi0_aloha_sim\")\n",
                "key = jax.random.key(0)\n",
                "\n",
                "# Create a model from the checkpoint.\n",
                "model = config.model.load(_model.restore_params(checkpoint_dir / \"params\"))\n",
                "\n",
                "# We can create fake observations and actions to test the model.\n",
                "obs, act = config.model.fake_obs(), config.model.fake_act()\n",
                "\n",
                "# Sample actions from the model.\n",
                "loss = model.compute_loss(key, obs, act)\n",
                "print(\"Loss shape:\", loss.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we are going to create a data loader and use a real batch of training data to compute the loss."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reduce the batch size to reduce memory usage.\n",
                "config = dataclasses.replace(config, batch_size=2)\n",
                "\n",
                "# Load a single batch of data. This is the same data that will be used during training.\n",
                "# NOTE: In order to make this example self-contained, we are skipping the normalization step\n",
                "# since it requires the normalization statistics to be generated using `compute_norm_stats`.\n",
                "loader = _data_loader.create_data_loader(config, num_batches=1, skip_norm_stats=True)\n",
                "obs, act = next(iter(loader))\n",
                "\n",
                "# Sample actions from the model.\n",
                "loss = model.compute_loss(key, obs, act)\n",
                "\n",
                "# Delete the model to free up memory.\n",
                "del model\n",
                "\n",
                "print(\"Loss shape:\", loss.shape)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
